---
theme: default
background: https://images.unsplash.com/photo-1518432031352-d6fc5c10da5a
title: Concurrencia en Go
info: |
  ## Concurrencia en Go
  Una investigaci√≥n t√©cnica profunda sobre la teor√≠a, implementaci√≥n y aplicaci√≥n pr√°ctica de la concurrencia en Go.
class: text-center
drawings:
  persist: false
transition: slide-left
mdc: true
---

# Concurrencia en Go

## Teor√≠a, Implementaci√≥n y Patrones

<div class="pt-12">
  <span @click="$slidev.nav.next" class="px-2 py-1 rounded cursor-pointer" hover:bg="white op-10">
    Presiona espacio para continuar <carbon:arrow-right class="inline"/>
  </span>
</div>

---
transition: fade-out
---

# ¬øQu√© vamos a ver?

<v-clicks>

- **Fundamentos** - Concurrencia vs Paralelismo
- **CSP** - Communicating Sequential Processes
- **Goroutines y Channels** - Los bloques fundamentales
- **Runtime Scheduler** - La magia detr√°s de escena
- **Patrones** - Soluciones idiom√°ticas
- **Context** - Control del ciclo de vida

</v-clicks>

---
layout: center
class: text-center
---

# Parte I: Fundamentos

## Conceptos esenciales de programaci√≥n concurrente

---

# Concurrencia vs Paralelismo

<div class="grid grid-cols-2 gap-4">

<div v-click>

## Concurrencia
- **Concepto estructural**
- Lidiar con muchas tareas a la vez
- Composici√≥n independiente
- Puede ejecutarse en un solo core

</div>

<div v-click>

## Paralelismo
- **Concepto de ejecuci√≥n**
- Hacer muchas cosas a la vez
- Requiere m√∫ltiples cores
- Ejecuci√≥n simult√°nea real

</div>

</div>

<div v-click class="mt-8 text-center text-gray-400">

*"Concurrency is about dealing with lots of things at once.*
*Parallelism is about doing lots of things at once."*
‚Äî Rob Pike

</div>

---

# Desaf√≠os en Programaci√≥n Concurrente

<v-clicks>

## Race Conditions
Cuando el resultado depende del orden impredecible de eventos

## Deadlocks  
Procesos bloqueados esperando recursos que otros tienen

## Livelocks
Procesos activos pero sin progreso real

## Starvation
Un proceso nunca obtiene los recursos que necesita

</v-clicks>

---

# Modelos de Concurrencia

<div class="text-sm">

| Caracter√≠stica | Memoria Compartida | CSP | Actor Model |
|---|---|---|---|
| **Abstracci√≥n** | Threads, Locks | Goroutines, Channels | Actors, Mailboxes |
| **Estado** | Expl√≠citamente compartido | Confinado, se comparte v√≠a mensajes | Encapsulado en actors |
| **Comunicaci√≥n** | Indirecta (memoria) | S√≠ncrona/As√≠ncrona (channels) | As√≠ncrona (mensajes) |
| **Acoplamiento** | Alto | Bajo | Muy Bajo |

</div>

<v-click>

<div class="mt-8 text-center">

Go eligi√≥ **CSP** para simplicidad y seguridad

</div>

</v-click>

---
layout: center
class: text-center
---

# Parte II: El Modelo Go

## CSP en la pr√°ctica

---

# La Filosof√≠a de Go

<div class="text-2xl font-bold text-center my-12">

"Don't communicate by sharing memory;
<span v-mark.underline.orange>share memory by communicating</span>"

</div>

<v-clicks>

## Modelo Tradicional
Los threads acceden a memoria compartida protegida por locks

## Modelo Go
Los valores se env√≠an entre goroutines a trav√©s de channels

</v-clicks>

---

# Goroutines

## La unidad de ejecuci√≥n concurrente

```go
// Lanzar una goroutine es trivial
go doSomething()

// Con funci√≥n an√≥nima
go func(msg string) {
    fmt.Println(msg)
}("hello")
```

<v-clicks>

### Caracter√≠sticas clave:
- **Ligeras**: Stack inicial de ~2KB (vs MB en threads OS)
- **Escalables**: Millones de goroutines simult√°neas
- **Gestionadas**: El runtime las multiplexa sobre threads OS

</v-clicks>

---

# Channels

## Los conductos de comunicaci√≥n

```go
// Crear channels
ch := make(chan int)        // Unbuffered
ch := make(chan string, 10) // Buffered

// Operaciones b√°sicas
ch <- 42      // Enviar
value := <-ch // Recibir
close(ch)     // Cerrar
```

<v-clicks>

### Unbuffered vs Buffered:
- **Unbuffered**: Sincronizaci√≥n directa (rendezvous)
- **Buffered**: Desacoplamiento temporal con capacidad

</v-clicks>

---

# Select Statement

## Multiplexaci√≥n de operaciones

```go
select {
case msg1 := <-ch1:
    fmt.Println("received", msg1)
case ch2 <- msg2:
    fmt.Println("sent", msg2)
case <-time.After(1 * time.Second):
    fmt.Println("timeout")
default:
    fmt.Println("no communication ready")
}
```

<v-click>

El `select` permite:
- Esperar en m√∫ltiples channels
- Implementar timeouts
- Operaciones no bloqueantes con `default`

</v-click>

---
layout: center
class: text-center
---

# Parte III: El Runtime Scheduler

## La maquinaria que hace posible la magia

---

# Arquitectura M:P:G

## El modelo de tres entidades

```mermaid {scale: 0.5}
graph LR
    G1[G1] --> P1[P1]
    G2[G2] --> P1
    G3[G3] --> P2[P2]
    P1 --> M1[M1]
    P2 --> M2[M2]
```

<div class="text-center mt-4">

El scheduler multiplexa **Goroutines** en **Machines** a trav√©s de **Processors**

</div>

---

# G - Goroutine

## La unidad de trabajo

<v-clicks>

- **Stack din√°mico**: Comienza con ~2KB, crece seg√∫n necesidad
- **Estado guardado**: Instruction pointer, registros, stack
- **Informaci√≥n de scheduling**: Estado (runnable, running, waiting)
- **Canales asociados**: Referencias a channels donde espera

</v-clicks>

<v-click>

```go
// Cada vez que escribes esto:
go func() {
    // trabajo...
}()
// Se crea un objeto 'g' en el runtime
```

</v-click>

---

# M - Machine Thread

## El ejecutor real

<v-clicks>

- **Thread del OS**: Contexto de ejecuci√≥n del kernel
- **Stack fijo**: ~8MB en sistemas Unix
- **Costo de cambio**: ~1-10Œºs para context switch del OS
- **Pool de threads**: El runtime mantiene un pool de Ms idle

</v-clicks>

<v-click>

<div class="mt-8 p-4 bg-gray-100 rounded">

üí° Go limita el n√∫mero de Ms activos para evitar sobrecarga del OS

</div>

</v-click>

---

# P - Processor

## El contexto de scheduling

<v-clicks>

- **N√∫mero fijo**: GOMAXPROCS (default = n√∫m. de CPUs)
- **Local Run Queue**: Cola privada de Gs listos (~256 max)
- **Cache de mcache**: Memoria local para allocations
- **Recursos de runtime**: Timers, network poller refs

</v-clicks>

<v-click>

```go
// Configurar el n√∫mero de Ps
runtime.GOMAXPROCS(4) // 4 procesadores l√≥gicos
```

</v-click>

---

# Work Stealing

## Algoritmo de b√∫squeda de trabajo

```mermaid {scale: 0.5}
flowchart LR
    Start[Buscar] --> Local[LRQ]
    Local -->|vac√≠a| Global[GRQ]
    Global -->|vac√≠a| Steal[Robar]
    Steal -->|falla| Poll[Poller]
    Local -->|ok| Exec[Ejecutar]
    Global -->|ok| Exec
    Steal -->|ok| Exec
    Poll -->|ok| Exec
```

---

# Detalles del Work Stealing

## Optimizaciones del algoritmo

<v-clicks>

### Local Run Queue primero
- Acceso sin locks
- Mejor localidad de cache
- Operaci√≥n m√°s r√°pida

### Global Run Queue (1/61)
- N√∫mero primo evita sincronizaci√≥n peri√≥dica
- Balance entre fairness y contenci√≥n
- Evita que GRQ sea bottleneck

### Robo de trabajo
- Selecci√≥n aleatoria de v√≠ctima
- Roba la mitad de las Gs
- Distribuye carga uniformemente

</v-clicks>

---

# Manejo de Bloqueos

## System calls bloqueantes

```mermaid {scale: 0.5}
sequenceDiagram
    participant G
    participant P
    participant M1
    participant M2
    
    G->>M1: syscall
    M1->>P: detach
    P->>M2: attach
    M2->>P: run Gs
    M1-->>G: done
    G-->>P: requeue
```

---

# Network Poller

## I/O as√≠ncrono integrado

<v-clicks>

### Mecanismo
- Usa epoll (Linux), kqueue (BSD), IOCP (Windows)
- Thread dedicado para polling
- Goroutines "estacionadas" no bloquean Ms

### Flujo
1. G intenta I/O en socket non-blocking
2. Si bloquear√≠a ‚Üí G se estaciona con poller
3. M queda libre para ejecutar otras Gs
4. Cuando I/O est√° listo ‚Üí G vuelve a run queue

### Ventaja
- Miles de conexiones concurrentes
- Sin thread por conexi√≥n
- Escalabilidad masiva para servidores

</v-clicks>

---

# Preemption As√≠ncrona

## Equidad desde Go 1.14

<v-clicks>

### Problema anterior
- Scheduling cooperativo
- Loops tight pod√≠an monopolizar P
- Starvation de otras goroutines

### Soluci√≥n actual
- Timer por goroutine (10ms)
- Se√±al as√≠ncrona si excede tiempo
- Fuerza yield y re-queue

</v-clicks>

<v-click>

```go
// Este loop ya no puede bloquear otras goroutines
for {
    // trabajo intensivo en CPU
    calculatePi()
}
// El runtime lo interrumpir√° cada 10ms
```

</v-click>

---
layout: center
class: text-center
---

# Parte IV: Patrones de Concurrencia

## Soluciones idiom√°ticas en Go

---

# Pipeline Pattern

## Procesamiento en etapas secuenciales

```mermaid {scale: 0.5}
graph LR
    Gen[Gen] -->|ch| T1[Trans1]
    T1 -->|ch| T2[Trans2]
    T2 -->|ch| Sink[Sink]
```

<v-clicks>

### Caracter√≠sticas
- Cada etapa es una goroutine independiente
- Channels conectan las etapas
- Datos fluyen unidireccionalmente
- F√°cil de componer y extender

</v-clicks>

---

# Pipeline: C√≥digo

## Implementaci√≥n del patr√≥n

```go
// Etapa generadora
func generator(nums...int) <-chan int {
    out := make(chan int)
    go func() {
        for _, n := range nums {
            out <- n
        }
        close(out)
    }()
    return out
}

// Etapa transformadora
func square(in <-chan int) <-chan int {
    out := make(chan int)
    go func() {
        for n := range in {
            out <- n * n
        }
        close(out)
    }()
    return out
}
```

---

# Fan-Out, Fan-In Pattern

## Paralelizaci√≥n din√°mica

```mermaid {scale: 0.5}
graph LR
    In[Input] --> W1[W1]
    In --> W2[W2]
    In --> W3[W3]
    W1 --> Out[Output]
    W2 --> Out
    W3 --> Out
```

<v-clicks>

- **Fan-out**: Distribuir trabajo entre workers
- **Fan-in**: Consolidar resultados en un canal
- **Uso**: Paralelizar etapas costosas del pipeline

</v-clicks>

---

# Fan-In: C√≥digo

## Consolidaci√≥n de m√∫ltiples channels

```go
// Fan-in: consolidar m√∫ltiples channels
func merge(cs...<-chan int) <-chan int {
    var wg sync.WaitGroup
    out := make(chan int)
    
    output := func(c <-chan int) {
        defer wg.Done()
        for n := range c {
            out <- n
        }
    }
    
    wg.Add(len(cs))
    for _, c := range cs {
        go output(c)
    }
    
    go func() {
        wg.Wait()
        close(out)
    }()
    return out
}
```

---

# Worker Pool Pattern

## Control de concurrencia limitada

```mermaid {scale: 0.5}
graph LR
    JQ[Jobs] --> W1[W1]
    JQ --> W2[W2]
    JQ --> W3[W3]
    W1 --> RQ[Results]
    W2 --> RQ
    W3 --> RQ
```

<v-clicks>

- **N√∫mero fijo de workers**: Limita paralelismo
- **Cola de trabajos compartida**: Distribuci√≥n autom√°tica
- **Ideal para**: APIs, DBs, recursos limitados

</v-clicks>

---

# Worker Pool: C√≥digo

## Implementaci√≥n con channels

```go
func worker(id int, jobs <-chan int, results chan<- int) {
    for j := range jobs {
        fmt.Printf("Worker %d procesando job %d\n", id, j)
        // Simular trabajo costoso
        time.Sleep(time.Second)
        results <- j * 2
    }
}

func main() {
    const numWorkers = 3
    jobs := make(chan int, 100)
    results := make(chan int, 100)
    
    // Iniciar workers
    for w := 1; w <= numWorkers; w++ {
        go worker(w, jobs, results)
    }
    
    // Enviar trabajos y recolectar resultados...
}
```

---

# Rate Limiting Pattern

## Control de throughput

```mermaid {scale: 0.5}
graph LR
    Req[Requests] --> RL[Limiter]
    RL --> Proc[Process]
```

<v-clicks>

### Estrategias
- **Ticker**: Tasa fija constante
- **Token Bucket**: Permite r√°fagas controladas
- **Sliding Window**: L√≠mite por ventana de tiempo

</v-clicks>

---

# Rate Limiting: Ticker

## Implementaci√≥n con tasa fija

```go
// Limitaci√≥n simple con ticker
limiter := time.NewTicker(200 * time.Millisecond)
defer limiter.Stop()

for req := range requests {
    <-limiter.C // Esperar hasta el pr√≥ximo tick
    go processRequest(req)
}
```

<v-click>

### Caracter√≠sticas
- Espaciado uniforme entre operaciones
- F√°cil de implementar
- No permite r√°fagas

</v-click>

---

# Rate Limiting: Token Bucket

## R√°fagas controladas

```go
// Token bucket para r√°fagas ocasionales
tokens := make(chan struct{}, 3) // M√°ximo 3 tokens

// Llenar bucket inicialmente
for i := 0; i < 3; i++ {
    tokens <- struct{}{}
}

// Reponer tokens peri√≥dicamente
go func() {
    ticker := time.NewTicker(time.Second)
    for range ticker.C {
        select {
        case tokens <- struct{}{}:
        default: // Bucket lleno, no agregar m√°s
        }
    }
}()

// Usar tokens para procesar
for req := range requests {
    <-tokens // Consumir un token
    go processRequest(req)
}
```

---
layout: center
class: text-center
---

# Parte V: Context Package

## Gesti√≥n del ciclo de vida

---

# Context para Control

## Cancelaci√≥n, deadlines y valores

```go
func worker(ctx context.Context) {
    for {
        select {
        case <-ctx.Done():
            fmt.Println("Worker cancelled")
            return
        default:
            // Hacer trabajo...
            time.Sleep(500 * time.Millisecond)
        }
    }
}

func main() {
    ctx, cancel := context.WithCancel(context.Background())
    go worker(ctx)
    
    time.Sleep(2 * time.Second)
    cancel() // Se√±alar al worker que pare
}
```

---

# Timeouts y Deadlines

## L√≠mites de tiempo en operaciones

```go
func slowOperation(ctx context.Context) (string, error) {
    select {
    case <-time.After(5 * time.Second):
        return "result", nil
    case <-ctx.Done():
        return "", ctx.Err() // DeadlineExceeded
    }
}

func main() {
    // Timeout de 3 segundos
    ctx, cancel := context.WithTimeout(
        context.Background(), 
        3 * time.Second,
    )
    defer cancel()
    
    _, err := slowOperation(ctx)
    if err != nil {
        fmt.Println("Operation failed:", err)
    }
}
```

---

# Composici√≥n de Patrones

<v-clicks>

## La verdadera potencia est√° en combinar:

1. **Pipeline** como estructura de alto nivel
2. **Fan-out/Fan-in** para paralelizar etapas intensivas
3. **Worker pools** para limitar concurrencia
4. **Context** para gesti√≥n del ciclo de vida
5. **Rate limiting** para controlar throughput

</v-clicks>

<v-click>

<div class="mt-8 p-4 bg-gray-100 rounded">

Estos patrones son **componibles** porque los channels son valores de primera clase

</div>

</v-click>

---
layout: center
class: text-center
---

# Parte VI: Recursos y Herramientas

## Para profundizar m√°s

---

# Herramientas Esenciales

<v-clicks>

## Race Detector
```bash
go run -race main.go
go test -race ./...
```
Detecta race conditions en tiempo de ejecuci√≥n

## pprof
```go
import _ "net/http/pprof"
// Analizar goroutines, CPU, memoria
```
Profiling para encontrar cuellos de botella

## Librer√≠as √∫tiles
- `golang.org/x/sync` - Primitivas de sincronizaci√≥n adicionales
- `golang.org/x/time/rate` - Rate limiting robusto

</v-clicks>

---

# Recursos Recomendados

<v-clicks>

## Libros
- **"The Go Programming Language"** - Donovan & Kernighan
- **"Concurrency in Go"** - Katherine Cox-Buday
- **"Learn Concurrent Programming with Go"** - James Cutajar

## Charlas de Rob Pike
- "Go Concurrency Patterns" (2012)
- "Concurrency is not Parallelism" (2012)

## Documentaci√≥n
- [Go Blog: Concurrency](https://go.dev/blog/pipelines)
- [Effective Go](https://go.dev/doc/effective_go)
- [Go Memory Model](https://go.dev/ref/mem)

</v-clicks>

---

# Mejores Pr√°cticas

<v-clicks>

## Hacer
- Usar channels para transferir ownership
- Aplicar context para gesti√≥n de lifecycle
- Limitar goroutines con worker pools
- Probar con `-race` siempre

## Evitar
- Compartir memoria sin sincronizaci√≥n
- Goroutines hu√©rfanas (leaks)
- Channels sin cerrar cuando corresponde
- Ignorar `ctx.Done()` en operaciones largas

</v-clicks>

---
layout: center
class: text-center
---

# Conclusi√≥n

<div class="text-xl mt-8">

Go transforma el desaf√≠o de la concurrencia en una herramienta accesible y poderosa

</div>

<v-clicks>

<div class="mt-8">

**CSP** + **Goroutines** + **Channels** = **Concurrencia Efectiva**

</div>

<div class="mt-4 text-gray-400">

Simple en la superficie, sofisticado por dentro

</div>

</v-clicks>

---
layout: center
class: text-center
---

# ¬øPreguntas?

## Experimenta con los patrones
## Lee el c√≥digo fuente del runtime
## Usa las herramientas

<div class="mt-12 text-gray-400">
Gracias por su atenci√≥n
</div>